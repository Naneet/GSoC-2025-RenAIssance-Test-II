{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjYtdJrnTFig",
        "scrolled": true
      },
      "outputs": [],
      "source": [
        "!curl -L -o ocr-dataset.zip https://www.kaggle.com/api/v1/datasets/download/naneet1/ocr-dataset\n",
        "!apt install unzip\n",
        "!unzip ocr-dataset.zip -d ocr-dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "2JKy0L0mfFKv"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install tiktoken\n",
        "!pip install protobuf\n",
        "!pip install sentencepiece"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHhYt_q-NGY7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torchvision import models, transforms\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torch.amp import autocast, GradScaler\n",
        "# from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "from transformers import ViTConfig, ViTModel, AutoTokenizer\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from PIL import Image\n",
        "import json\n",
        "import os\n",
        "# from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ot5MJY2NRum"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "# Open and read the JSON file\n",
        "with open(\"/home/ocr-dataset/OCR_Images/labels.json\", \"r\", encoding=\"utf-8\") as file:\n",
        "    data = json.load(file)  # Load JSON content into a Python dictionary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nSmPuVSgfFKw",
        "outputId": "42bfe762-d230-4085-fed5-0edcd2c6b13a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pad Token: <pad>\n",
            "Pad Token ID: 1\n",
            "Special Tokens: {'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'sep_token': '</s>', 'pad_token': '<pad>', 'cls_token': '<s>', 'mask_token': '<mask>'}\n",
            "SOS Token: <s>\n",
            "SOS Token ID: 0\n",
            "EOS Token: </s>\n",
            "EOS Token ID: 2\n",
            "Vocab Size: 250002\n"
          ]
        }
      ],
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('xlm-roberta-base')\n",
        "\n",
        "print(\"Pad Token:\", tokenizer.pad_token)\n",
        "print(\"Pad Token ID:\", tokenizer.pad_token_id)\n",
        "\n",
        "print(\"Special Tokens:\", tokenizer.special_tokens_map)\n",
        "\n",
        "# Print SOS and EOS (if they exist)\n",
        "print(\"SOS Token:\", tokenizer.bos_token)\n",
        "print(\"SOS Token ID:\", tokenizer.bos_token_id)\n",
        "\n",
        "print(\"EOS Token:\", tokenizer.eos_token)\n",
        "print(\"EOS Token ID:\", tokenizer.eos_token_id)\n",
        "\n",
        "print(\"Vocab Size:\", tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lMi31xEvNUzP"
      },
      "outputs": [],
      "source": [
        "class Custom_OCR_Dataset(Dataset):\n",
        "    def __init__(self, data, transform=None, tokenizer=tokenizer):\n",
        "        \"\"\"\n",
        "        Custom dataset to load images and text labels from extracted PDFs.\n",
        "\n",
        "        :param data_folder: Path to the output folder containing images & labels.json.\n",
        "        :param transform: Transformations for image preprocessing (optional).\n",
        "        \"\"\"\n",
        "        self.data = data\n",
        "        self.transform = transform\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        root = \"/home/ocr-dataset/OCR_Images/\"\n",
        "        img_path = os.path.join(root, self.data[idx]['image'].split(\"\\\\\")[-2], self.data[idx]['image'].split(\"\\\\\")[-1])\n",
        "        raw_text = self.data[idx]['text']\n",
        "        img = Image.open(img_path)\n",
        "        tensor_img = self.transform(img)\n",
        "        tokenized_text = self.tokenizer(raw_text, padding=True, truncation=True, max_length=512, stride=128, return_tensors=\"pt\")\n",
        "        return tensor_img, tokenized_text[\"input_ids\"].squeeze(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RwM_CDl-NWyd"
      },
      "outputs": [],
      "source": [
        "def collate_fn(batch):\n",
        "    images, labels = zip(*batch)\n",
        "    images = torch.stack(images)\n",
        "\n",
        "    sequence_lens = [len(label) for label in labels]\n",
        "    max_len = max(sequence_lens)\n",
        "\n",
        "    padded_labels = torch.zeros(len(labels), max_len, dtype=torch.long)\n",
        "    for i, label in enumerate(labels):\n",
        "        padded_labels[i, :len(label)] = label\n",
        "\n",
        "    return images, padded_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SAFAz7ZANXUX"
      },
      "outputs": [],
      "source": [
        "test_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize((768,768))\n",
        "])\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomRotation((-5,5), expand=True),\n",
        "    transforms.RandomApply(\n",
        "        [transforms.GaussianBlur((5,5))],\n",
        "        p=0.5\n",
        "    ),\n",
        "    transforms.Resize((768,768))\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ll8Vj3FONbrm"
      },
      "outputs": [],
      "source": [
        "dataset = Custom_OCR_Dataset(data=data, transform=test_transform)\n",
        "\n",
        "train_size = int(0.8 * len(dataset))\n",
        "test_size = len(dataset) - train_size\n",
        "\n",
        "torch.manual_seed(42)\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=3, shuffle=True, collate_fn=collate_fn)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=3, shuffle=False, collate_fn=collate_fn)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X28NG588NjKz",
        "outputId": "e43ea1e4-1202-4c01-ba36-2ce3cdbb6641"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 3, 768, 768]), torch.Size([3, 512]))"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "img, label = next(iter(train_dataloader))\n",
        "img.shape, label.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4dTFMAilOJW8"
      },
      "outputs": [],
      "source": [
        "class VV_OCR(nn.Module):\n",
        "    def __init__(self,\n",
        "                 vocab_size=tokenizer.vocab_size,\n",
        "                 vit_config=ViTConfig(image_size=768, hidden_size=768, intermediate_size=3072, num_attention_heads=12),\n",
        "                 d_model=768,\n",
        "                 nhead=8,\n",
        "                 num_decoder_layers=6,\n",
        "                 dim_feedforward=3072,\n",
        "                 dropout=0.1,\n",
        "                 batch_first=True,\n",
        "                 pad_token=tokenizer.pad_token_id,\n",
        "                 sos_token=tokenizer.bos_token_id,\n",
        "                 eos_token=tokenizer.eos_token_id,\n",
        "                 max_pred=512):\n",
        "\n",
        "        super(OCR_V3, self).__init__()\n",
        "\n",
        "        self.vit = ViTModel(vit_config)\n",
        "\n",
        "        decoder_layer = nn.TransformerDecoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward, dropout=dropout, batch_first=batch_first)\n",
        "        self.decoder = nn.TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
        "\n",
        "        self.pad_token = pad_token\n",
        "        self.sos_token = sos_token\n",
        "        self.eos_token = eos_token\n",
        "        self.vocab_size = vocab_size\n",
        "\n",
        "        self.embedding = nn.Embedding(vocab_size, d_model, padding_idx=pad_token)\n",
        "        self.max_pred = max_pred\n",
        "\n",
        "        self.fc_out = nn.Linear(d_model, vocab_size)\n",
        "\n",
        "\n",
        "    def forward(self, img, y_tokens):\n",
        "\n",
        "        encoded_output = self.vit(img).last_hidden_state\n",
        "\n",
        "        if y_tokens.shape[-1] == 1:\n",
        "            all_logits = torch.zeros(self.vocab_size).unsqueeze(0).unsqueeze(0).to(device)\n",
        "\n",
        "            for i in range(self.max_pred-2):\n",
        "                y_embedded = self.embedding(y_tokens)\n",
        "\n",
        "                decoded_output = self.decoder(y_embedded, encoded_output)\n",
        "                logit = self.fc_out(decoded_output)\n",
        "                all_logits = torch.cat([all_logits, logit[:,-1,:].unsqueeze(0)], dim=-2)\n",
        "\n",
        "\n",
        "                last_output_token = logit[:,-1,:].argmax(1).unsqueeze(0)\n",
        "                y_tokens = torch.cat([y_tokens, last_output_token], dim=1)\n",
        "\n",
        "                if last_output_token == self.eos_token:\n",
        "                    return y_tokens, all_logits\n",
        "\n",
        "            else:\n",
        "                y_tokens = torch.cat([y_tokens, torch.tensor([[self.eos_token]]).to(device)], dim=1)\n",
        "                return y_tokens, all_logits\n",
        "\n",
        "        else:\n",
        "            y_embedded = self.embedding(y_tokens)\n",
        "\n",
        "            tgt_seq_len = y_embedded.shape[1]\n",
        "            tgt_mask = nn.Transformer.generate_square_subsequent_mask(tgt_seq_len).to(y_embedded.device)\n",
        "\n",
        "            tgt_key_padding_mask = (y_tokens == self.pad_token)\n",
        "\n",
        "            decoded_output = self.decoder(y_embedded, encoded_output, tgt_mask=tgt_mask, tgt_key_padding_mask=tgt_key_padding_mask)\n",
        "\n",
        "            logit = self.fc_out(decoded_output)\n",
        "\n",
        "            return logit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dQ-cxFG7RVfp"
      },
      "outputs": [],
      "source": [
        "def add_noise_to_sequence(seq, vocab_size=tokenizer.vocab_size, noise_prob=0.1):\n",
        "\n",
        "    rand_mask = torch.rand_like(seq.float())  # Random values in [0, 1]\n",
        "    replace_mask = rand_mask < noise_prob\n",
        "    random_tokens = torch.randint(0, vocab_size, seq.shape, dtype=seq.dtype, device=seq.device)\n",
        "\n",
        "    noisy_seq = torch.where(replace_mask, random_tokens, seq)\n",
        "    return noisy_seq\n",
        "\n",
        "\n",
        "def train_step(model, optimizer, dataloader, loss_fn, epoch):\n",
        "    model.train()\n",
        "    train_loss, total_correct, total_sample = 0, 0, 0\n",
        "\n",
        "    for X, y in tqdm(dataloader, total=len(dataloader), desc=\"Training\", unit=\"images\"):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        y_noise = add_noise_to_sequence(y, noise_prob=0.3)\n",
        "\n",
        "        y_logit = model(X, y)\n",
        "\n",
        "        loss = loss_fn(y_logit.permute(0,2,1), y)\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        y_pred = torch.argmax(y_logit, dim=2)\n",
        "        total_correct += (y_pred == y).sum().item()\n",
        "        total_sample += y_pred.numel()\n",
        "        del X, y, y_logit, loss, y_pred\n",
        "\n",
        "    acc = (total_correct / total_sample) * 100\n",
        "    avg_loss = train_loss / len(dataloader)\n",
        "\n",
        "    print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | Accuracy: {acc:.2f}%\")\n",
        "\n",
        "def test_step(model, loss_fn, epoch, dataloader):\n",
        "    model.eval()\n",
        "    test_loss, total_correct, total_sample = 0, 0, 0\n",
        "    with torch.inference_mode():\n",
        "        for X, y in tqdm(dataloader, total=len(dataloader), desc=\"Testing\", unit=\"images\"):\n",
        "            X, y = X.to(device), y.to(device)\n",
        "\n",
        "            y_logit = model(X, y)\n",
        "\n",
        "            loss = loss_fn(y_logit.permute(0,2,1), y)\n",
        "            test_loss += loss.item()\n",
        "\n",
        "            y_pred = torch.argmax(y_logit, dim=2)\n",
        "            total_correct += (y_pred == y).sum().item()\n",
        "            total_sample += y_pred.numel()\n",
        "            del X, y, y_logit, loss, y_pred\n",
        "\n",
        "    acc = (total_correct / total_sample) * 100\n",
        "    avg_loss = test_loss / len(dataloader)\n",
        "\n",
        "    print(f\"Epoch {epoch} | Loss: {avg_loss:.4f} | Accuracy: {acc:.2f}%\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoN1AFZ8R0jL",
        "outputId": "d15420c7-fb05-41a2-dce2-bd49b3e27207"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2035/1496748172.py:9: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  model.load_state_dict(torch.load(f=\"/home/Tr_Only_English.pth\"))\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "\n",
        "device='cuda'\n",
        "\n",
        "configuration = ViTConfig(image_size=768, hidden_size=768, intermediate_size=3072, num_attention_heads=12)\n",
        "\n",
        "model = VV_OCR(vocab_size=tokenizer.vocab_size, vit_config=configuration).to(device)\n",
        "model.load_state_dict(torch.load(f=\"/home/Tr_Only_English.pth\"))\n",
        "# model = nn.DataParallel(model)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 436,
          "referenced_widgets": [
            "a8eae2d9346c4b4daf9b7b7edcb3f059",
            "1354b538ad2840cd8cd17a134b7ac295",
            "863fa295ae5c4f579d53b70b03312981",
            "d1755ff795a94c8995c11dd8946c276c",
            "4a6a472dfa694872af0e5faff39c3049",
            "30b8e66ccf7840709442f6e3b296856a",
            "f08458e1e5064c37b6e3a406651625d2",
            "2b1b1cd1c331412096fdffe99c443fa5",
            "1bb87fa2acf34ed29df2467cfa64cfba",
            "3b3905a16e4f4202960680b36e1cb09a",
            "922ffbc29edb4cc7b97569c8462ecf7e",
            "4651a358df9a4eaea4be6b20618e46b7",
            "b6267097d6b149d983f29c52f72c9372"
          ]
        },
        "id": "eP72OUL3R2yU",
        "outputId": "5ed90bae-858b-4cc9-b034-1546f9c7cdf2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4651a358df9a4eaea4be6b20618e46b7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Training:   0%|          | 0/1547 [00:00<?, ?images/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/conda/lib/python3.11/site-packages/torch/nn/functional.py:5849: UserWarning: Support for mismatched key_padding_mask and attn_mask is deprecated. Use same type for both instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss: 1.6207 | Accuracy: 84.71%\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b6267097d6b149d983f29c52f72c9372",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Testing:   0%|          | 0/387 [00:00<?, ?images/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0 | Loss: 0.2304 | Accuracy: 98.62%\n"
          ]
        }
      ],
      "source": [
        "epochs = 1\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "for epoch in range(epochs):\n",
        "  train_step(model=model,\n",
        "             optimizer=optimizer,\n",
        "             loss_fn=loss_fn,\n",
        "             epoch=epoch,\n",
        "             dataloader=train_dataloader)\n",
        "  test_step(model=model,\n",
        "            loss_fn=loss_fn,\n",
        "            epoch=epoch,\n",
        "            dataloader=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lIJtXRgJR5vA"
      },
      "outputs": [],
      "source": [
        "torch.save(obj=model.state_dict(), f=\"Tr_Only_English.pth\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVHG_Z7vR7Mi"
      },
      "outputs": [],
      "source": [
        "from IPython.display import FileLink\n",
        "FileLink('Tr_Only_Spanish.pth')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TDV3z4uaR85R"
      },
      "outputs": [],
      "source": [
        "# model.load_state_dict(torch.load(f='/kaggle/working/Tr_Only_Checking.pth'))\n",
        "\n",
        "test_step(model=model,\n",
        "        loss_fn=loss_fn,\n",
        "        epoch=1,\n",
        "        dataloader=test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93CBIzhAfFKy"
      },
      "outputs": [],
      "source": [
        "x, y = test_dataset[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2OL7YzTfFKy",
        "outputId": "3f716abd-2aa6-495b-b1a1-03d2f7f8dcd5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(torch.Size([3, 768, 768]), torch.Size([512]))"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "x.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u_rVXFerfFKz"
      },
      "outputs": [],
      "source": [
        "output = model(x.unsqueeze(0).to(device),y.unsqueeze(0).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OwbLt67MfFKz",
        "outputId": "59b3d201-2788-4f09-cb5d-19e38dd54982"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([     0,      6, 237366,    541,    170, 102617,      4,   3036,  31746,\n",
              "             4,    821,   6505,      4,    136,    339,   6921,   2082,      5,\n",
              "           563,    150,  11050,     12,     62,   8347,    111,  58663,  22729,\n",
              "         17055,   2320,  28029,    223,      4,  57553,      7,      4,    136,\n",
              "         10548,      9,   9077,      7,      5,  30948,    214,  42477,    619,\n",
              "         46473,      4,   4859,  27750,     12,    758,   1104,   5843,      4,\n",
              "        140429,      5,    305,    378,   8894,    268,  20681,   1720,   9315,\n",
              "            11,   1399,    353,    420,   1861,      4,     62,  94207,  14318,\n",
              "         24004,   1399,      4,  11653,  15080,   1065, 114137,      4,    136,\n",
              "         65261,   5024,   5428,      5,   1215,     66,  30170,   2320,  21373,\n",
              "          2481,  63262,     12,    241,  24500,  45964,    136, 215543,   4393,\n",
              "             9, 239879,  29569,  31897, 151575,    748,      5,     87, 129969,\n",
              "         40266,      4,    201,  12498,  22377,   1104,  11663,   5039,      4,\n",
              "          6360,    382,    378,  13023,    268,   5379,    908,   1255,      9,\n",
              "         19060,    118,    169,    136, 118568,    141,    341,      5,   1572,\n",
              "           118,   2247,      5,     62, 138155,  17997,    136,  10975,    100,\n",
              "         60822,    214,  80836,  90825, 225490, 136303,      9,      6,   9035,\n",
              "             5,     15,    147,   1542,   4371,  22950,   1530,      5,   9513,\n",
              "        178475,    247,   5276,    187,   1542,   4371,  22950,   1530,      5,\n",
              "          9513, 178475,    378,   4439,      4,  13254,    268,      5,    106,\n",
              "           378,  11548,    268,   5379,    908,   1255,      9,  19060,    118,\n",
              "           169,      4,   2132,   2273,   1399,   1208,  11395,   2104,   2247,\n",
              "             4,  37385,  68433,    669,      4,   8115,    712,    297,  27744,\n",
              "             4, 105950,   4769,      9,    184,      4,    136, 118568,    141,\n",
              "           341,      5,   1572,    118,   2247,      5,  28090,  80836,  90825,\n",
              "        225490,      7,    136,  66038,     47,     10,     51,  47314,   7002,\n",
              "             9,  25586, 105994,      5,     87, 129969,  11062,  44713,      7,\n",
              "            98,  22710, 123996,    214,      4,   1702,     12,    534,   9323,\n",
              "        104279, 135224,      4,  83489,    106,      6, 241446, 171147,  47691,\n",
              "           157,      4,  10440,   5861,    873,   3443,    219,   6470,   1255,\n",
              "             4,    136,  60701,  19895,     90,      5, 113837,  16106,  57860,\n",
              "            12, 151228,   1916,    933,   7002,      9,  25586, 115774,    678,\n",
              "            70,    158,   9297, 122009, 118555,   3956,  63262,      5,     87,\n",
              "        129969,  11062,  44713,      7,     98,    602,      4,   9191,    106,\n",
              "          1104,   2681,      4,  76924,      5,    106,      4,    116,    378,\n",
              "          4633,    268,  63931,  21320, 183140,      4,  58685,  66235,     13,\n",
              "             4,   5174,   2310,   1461,    939,     93,    685,      4,    136,\n",
              "         14978,   4887,   1972,     71,      5,     62,  46638,    259,   2601,\n",
              "           126,      9,  77007,  34564,  39181,  21373,      9,  25586,  63262,\n",
              "           100,  29569,  31897, 164031,      5, 144000, 123996,    214,     12,\n",
              "         22710,  87398,      4,  11716,  31191,   1104,  11548,      4,   4152,\n",
              "           382,    378,   9271,    268,   4939,    527,  30520,   1681,      5,\n",
              "         10959,    118,    289,    136,  58663,  69822,      9, 176302,   2481,\n",
              "         32354,      7,    111,     70,  21176,   5426,      5,    821,  95487,\n",
              "             4,   9103,    132,  50490,  19993,   8894, 104279, 152837,      4,\n",
              "            62,      5,    106,      4,    201,    378,  13330,    268,  11852,\n",
              "        113054,   2777,  48225,      4,  98908,     14,  11809,   2967,      4,\n",
              "           136,    627,   5176,    541,  95353,    162,  95353,     66,     33,\n",
              "             5,  16269,      9,     88,   2069,     70,      6, 215131,    111,\n",
              "         69822,      6, 176302,   2481,     98,   4224,   1916,  16128,    136,\n",
              "          5623,    118,    289,  12478,    944,  27771,      5,   7275,      5,\n",
              "          9624,      5,      4,   3912, 145666,     16,  27592,  13574,   1104,\n",
              "           304, 146406,      4, 106540,    305,    378,   9285,    268,  11852,\n",
              "        113054,   2777,  48225,      4,   3314,    686,   6609,  94266,      4,\n",
              "           136,    627,   5176,    541,  95353,    162,  95353,     66,     33,\n",
              "             5,    799,  82451,  17055,   2320,  12302,  32354,    111,     70,\n",
              "         14135,  21176,   5426,     99,  67842,   3362,     19,      2],\n",
              "       device='cuda:0')"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output.squeeze(0).argmax(dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "la895YdNfFKz",
        "outputId": "bbb2a3fd-5432-46f4-ed38-b70000d3f0e0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([ True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        False,  True,  True,  True,  True, False,  True, False, False,  True,\n",
              "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True, False,  True,  True,  True,  True,  True,  True, False,\n",
              "        False,  True,  True,  True,  True, False,  True,  True, False,  True,\n",
              "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
              "         True,  True,  True, False, False,  True, False,  True, False,  True,\n",
              "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True, False, False,  True, False,\n",
              "         True,  True,  True, False, False,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
              "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
              "         True,  True])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y == output.squeeze(0).argmax(dim=1).to('cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qU_dpFxJfFKz"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MwnqyFRfFKz"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "    output_2 = model(x.unsqueeze(0).to(device),torch.tensor([[0]]).to(device))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "POWpCQ3bfFKz",
        "outputId": "e63866ec-ad97-4676-8e5a-0d044030f9bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "         0, 0, 0, 0, 0, 0, 0, 2]], device='cuda:0')"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "output_2[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p8hXUqWqfFKz"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1354b538ad2840cd8cd17a134b7ac295": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30b8e66ccf7840709442f6e3b296856a",
            "placeholder": "​",
            "style": "IPY_MODEL_f08458e1e5064c37b6e3a406651625d2",
            "value": "Training:   1%"
          }
        },
        "1bb87fa2acf34ed29df2467cfa64cfba": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2b1b1cd1c331412096fdffe99c443fa5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30b8e66ccf7840709442f6e3b296856a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3b3905a16e4f4202960680b36e1cb09a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a6a472dfa694872af0e5faff39c3049": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "863fa295ae5c4f579d53b70b03312981": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2b1b1cd1c331412096fdffe99c443fa5",
            "max": 4640,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1bb87fa2acf34ed29df2467cfa64cfba",
            "value": 40
          }
        },
        "922ffbc29edb4cc7b97569c8462ecf7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8eae2d9346c4b4daf9b7b7edcb3f059": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1354b538ad2840cd8cd17a134b7ac295",
              "IPY_MODEL_863fa295ae5c4f579d53b70b03312981",
              "IPY_MODEL_d1755ff795a94c8995c11dd8946c276c"
            ],
            "layout": "IPY_MODEL_4a6a472dfa694872af0e5faff39c3049"
          }
        },
        "d1755ff795a94c8995c11dd8946c276c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3b3905a16e4f4202960680b36e1cb09a",
            "placeholder": "​",
            "style": "IPY_MODEL_922ffbc29edb4cc7b97569c8462ecf7e",
            "value": " 40/4640 [01:02&lt;1:52:45,  1.47s/images]"
          }
        },
        "f08458e1e5064c37b6e3a406651625d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}